{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Koala Detection Project\n",
    "\n",
    "#This notebook covers the entire workflow from installing necessary libraries to training and exporting an object detection model for Koala detection using TensorFlow Object Detection API.\n",
    "\n",
    "## Step 1: Install Necessary Libraries\n",
    "\n",
    "#```python\n",
    "!pip install tensorflow\n",
    "!pip install tf_slim\n",
    "!pip install pycocotools\n",
    "!pip install lvis\n",
    "!pip install contextlib2\n",
    "!pip install matplotlib\n",
    "!pip install pillow\n",
    "\n",
    "# Clone the TensorFlow models repository\n",
    "!git clone --depth 1 https://github.com/tensorflow/models\n",
    "\n",
    "# Install the Object Detection API\n",
    "%cd models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "!cp object_detection/packages/tf2/setup.py .\n",
    "!pip install .\n",
    "\n",
    "# Verify the installation\n",
    "!python object_detection/builders/model_builder_tf2_test.py\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "# Define the model to download\n",
    "MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "BASE_DIR = r'C:\\Users\\arron\\OneDrive\\Documents\\UTS\\Post Graduate\\Semester 2\\42028 Deep Learning and Convolutional Neural Networks\\Assignments\\Assignment 3\\Part E'\n",
    "MODEL_DIR = os.path.join(BASE_DIR, 'koala_model')\n",
    "MODEL_URL = f'http://download.tensorflow.org/models/object_detection/tf2/20200711/{MODEL_NAME}.tar.gz'\n",
    "\n",
    "# Create a directory for the model\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Download the model\n",
    "model_path = os.path.join(MODEL_DIR, f'{MODEL_NAME}.tar.gz')\n",
    "urllib.request.urlretrieve(MODEL_URL, model_path)\n",
    "\n",
    "# Extract the model\n",
    "with tarfile.open(model_path) as tar:\n",
    "    tar.extractall(path=MODEL_DIR)\n",
    "\n",
    "print(f\"Model {MODEL_NAME} downloaded and extracted successfully!\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "from object_detection.utils import dataset_util\n",
    "\n",
    "# Define the label map\n",
    "label_map = {\n",
    "    \"background\": 0,\n",
    "    \"koalas\": 1\n",
    "}\n",
    "\n",
    "def create_tf_example(annotation_path, image_path):\n",
    "    with open(annotation_path) as fid:\n",
    "        xml_str = fid.read()\n",
    "    xml = ET.fromstring(xml_str)\n",
    "    filename = xml.find('filename').text\n",
    "    img_path = os.path.join(image_path, filename)\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Image file {img_path} not found.\")\n",
    "        return None\n",
    "    with tf.io.gfile.GFile(img_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    size = xml.find('size')\n",
    "    width = int(size.find('width').text)\n",
    "    height = int(size.find('height').text)\n",
    "\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for member in xml.findall('object'):\n",
    "        class_name = member.find('name').text\n",
    "        if class_name in label_map:\n",
    "            class_id = label_map[class_name]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        xmin = float(member.find('bndbox').find('xmin').text) / width\n",
    "        xmax = float(member.find('bndbox').find('xmax').text) / width\n",
    "        ymin = float(member.find('bndbox').find('ymin').text) / height\n",
    "        ymax = float(member.find('bndbox').find('ymax').text) / height\n",
    "        xmins.append(xmin)\n",
    "        xmaxs.append(xmax)\n",
    "        ymins.append(ymin)\n",
    "        ymaxs.append(ymax)\n",
    "        classes_text.append(class_name.encode('utf8'))\n",
    "        classes.append(class_id)\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "def create_tf_record(output_path, annotation_dir, image_dir):\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    writer = tf.io.TFRecordWriter(output_path)\n",
    "    annotation_paths = glob.glob(os.path.join(annotation_dir, '*.xml'))\n",
    "    for annotation_path in annotation_paths:\n",
    "        tf_example = create_tf_example(annotation_path, image_dir)\n",
    "        if tf_example is not None:\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "\n",
    "# Define paths\n",
    "output_path = r'C:\\Users\\arron\\OneDrive\\Documents\\UTS\\Post Graduate\\Semester 2\\42028 Deep Learning and Convolutional Neural Networks\\Assignments\\Assignment 3\\Part E\\koala_dataset\\koala annotated dataset\\train.record'\n",
    "annotation_dir = r'C:\\Users\\arron\\OneDrive\\Documents\\UTS\\Post Graduate\\Semester 2\\42028 Deep Learning and Convolutional Neural Networks\\Assignments\\Assignment 3\\Downloaded Dataset\\koala annotated dataset\\Annotations'\n",
    "image_dir = r'C:\\Users\\arron\\OneDrive\\Documents\\UTS\\Post Graduate\\Semester 2\\42028 Deep Learning and Convolutional Neural Networks\\Assignments\\Assignment 3\\Downloaded Dataset\\koala annotated dataset\\images'\n",
    "\n",
    "# Create TFRecord\n",
    "create_tf_record(output_path, annotation_dir, image_dir)\n",
    "print(\"TFRecord created successfully!\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "# Define paths\n",
    "model_dir = os.path.join(BASE_DIR, 'koala_model/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8')\n",
    "pipeline_config_path = os.path.join(model_dir, 'pipeline.config')\n",
    "label_map_path = os.path.join(BASE_DIR, 'koala_dataset/koala annotated dataset/label_map.pbtxt')\n",
    "train_record_path = os.path.join(BASE_DIR, 'koala_dataset/koala annotated dataset/train.record')\n",
    "\n",
    "# Load pipeline config and modify it\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_config_path)\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(pipeline_config_path, \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)\n",
    "\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [train_record_path]\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [train_record_path]\n",
    "pipeline_config.train_input_reader.label_map_path = label_map_path\n",
    "pipeline_config.eval_input_reader[0].label_map_path = label_map_path\n",
    "pipeline_config.model.ssd.num_classes = 1  # Assuming one class (koala)\n",
    "\n",
    "# Save updated pipeline config\n",
    "config_util.save_pipeline_config(pipeline_config, model_dir)\n",
    "print(\"Pipeline configuration updated successfully!\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BASH CODE NEXT"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Ensure you're in the right directory\n",
    "cd models/research\n",
    "\n",
    "# Train the model\n",
    "python model_main_tf2.py \\\n",
    "    --model_dir=\"C:\\Users\\arron\\OneDrive\\Documents\\UTS\\Post Graduate\\Semester 2\\42028 Deep Learning and Convolutional Neural Networks\\Assignments\\Assignment 3\\Part E\\koala_model\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\" \\\n",
    "    --pipeline_config_path=\"C:\\Users\\arron\\OneDrive\\Documents\\UTS\\Post Graduate\\Semester 2\\42028 Deep Learning and Convolutional Neural Networks\\Assignments\\Assignment 3\\Part E\\koala_model\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\pipeline.config\" \\\n",
    "    --num_train_steps=2000 \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --alsologtostderr\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!python model_main_tf2.py \\\n",
    "    --model_dir=\"C:\\Users\\arron\\OneDrive\\Documents\\UTS\\Post Graduate\\Semester 2\\42028 Deep Learning and Convolutional Neural Networks\\Assignments\\Assignment 3\\Part E\\koala_model\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\" \\\n",
    "    --pipeline_config_path=\"C:\\Users\\arron\\OneDrive\\Documents\\UTS\\Post Graduate\\Semester 2\\42028 Deep Learning and Convolutional Neural Networks\\Assignments\\Assignment 3\\Part E\\koala_model\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\pipeline.config\" \\\n",
    "    --checkpoint_dir=\"C:\\Users\\arron\\OneDrive\\Documents\\UTS\\Post Graduate\\Semester 2\\42028 Deep Learning and Convolutional Neural Networks\\Assignments\\Assignment 3\\Part E\\koala_model\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\" \\\n",
    "    --eval_training_data=True \\\n",
    "    --alsologtostderr\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!python exporter_main_v2.py \\\n",
    "    --input_type image_tensor \\\n",
    "    --pipeline_config_path=\"C:\\Users\\arron\\OneDrive\\Documents\\UTS\\Post Graduate\\Semester 2\\42028 Deep Learning and Convolutional Neural Networks\\Assignments\\Assignment 3\\Part E\\koala_model\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\pipeline.config\" \\\n",
    "    --trained_checkpoint_dir=\"C:\\Users\\arron\\OneDrive\\Documents\\UTS\\Post Graduate\\Semester 2\\42028 Deep Learning and Convolutional Neural Networks\\Assignments\\Assignment 3\\Part E\\koala_model\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\" \\\n",
    "    --output_directory=\"C:\\Users\\arron\\OneDrive\\Documents\\UTS\\Post Graduate\\Semester 2\\42028 Deep Learning and Convolutional Neural Networks\\Assignments\\Assignment 3\\Part E\\koala_model\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\exported_model\"\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
